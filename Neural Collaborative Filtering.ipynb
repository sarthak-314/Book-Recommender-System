{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Collaborative.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fkFxXygxt642ENw4tFpl32h65aWCoPxU",
      "authorship_tag": "ABX9TyPmFEvFgNj1v05sKMMzu/RZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarthak-314/Book-Recommender-System/blob/master/Neural%20Collaborative%20Filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InK_isp2qGy7",
        "colab_type": "text"
      },
      "source": [
        "#**Neural Collaborative Filtering** with Keras\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlS-921tAWDo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9452c999-c5d7-4a5e-d73a-b852ac6d6f43"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "%cd /content/drive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wyo5f0POBfGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DF_PATH = './Colab Notebooks/CADABRA/Recommender System/goodreads-10k'\n",
        "ratings = pd.read_csv(os.path.join(DF_PATH, 'ratings.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP8bNdwyJey9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "616184dd-910b-4f96-ef52-370a35f8fc4a"
      },
      "source": [
        "ratings.rating.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    2139018\n",
              "5    1983093\n",
              "3    1370916\n",
              "2     359257\n",
              "1     124195\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ine9h7YCJ8mc",
        "colab_type": "text"
      },
      "source": [
        "**Combining 1 star, 2 star and 3 star ratings**\n",
        "\n",
        "The ratings for the books are heavily skewed towards 4 star (2.1M) and 5 star (1.98M) ratings\n",
        "\n",
        "There are not that many 1 star (124K) and 2 star (359 K) ratings in the dataset. So I balance out the ratings by combining 1 star, 2 star and 3 star ratings (total=1.8M) into one feature. This way all the columns will have close to 2 million ratings availible and the dataset will be balanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPUfXr63JmwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "aa941ccc-ef3a-4201-96a8-9f72142a6396"
      },
      "source": [
        "#One Hot encoding along with combining 1, 2, 3 star ratings\n",
        "\n",
        "#5 star ratings go into loved_book column\n",
        "ratings['loved_book'] = (ratings.rating == 5).astype(int)\n",
        "#4 star ratings go into liked_book column\n",
        "ratings['liked_book'] = (ratings.rating == 4).astype(int)\n",
        "#Ratings less than 4 go into did_not_like column\n",
        "ratings['did_not_like'] = (ratings.rating < 4).astype(int)\n",
        "\n",
        "ratings.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>book_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>loved_book</th>\n",
              "      <th>liked_book</th>\n",
              "      <th>did_not_like</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>258</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4081</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>260</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>9296</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>2318</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  book_id  rating  loved_book  liked_book  did_not_like\n",
              "0        1      258       5           1           0             0\n",
              "1        2     4081       4           0           1             0\n",
              "2        2      260       5           1           0             0\n",
              "3        2     9296       5           1           0             0\n",
              "4        2     2318       3           0           0             1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJaaaF6Szcsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TOTAL_USERS = ratings.user_id.nunique()\n",
        "TOTAL_BOOKS = ratings.book_id.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp08a9D01IGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "X = np.stack([ratings.user_id.values, ratings.book_id.values], axis=-1)\n",
        "Y = np.stack([ratings.loved_book, ratings.liked_book, ratings.did_not_like], axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysw4wmHSNXrL",
        "colab_type": "text"
      },
      "source": [
        "In the dataset, user_id and book_id start from 1. But numpy and python follow a 0-based indexing rule. So user_id = 1 will be at row = 0, user_id = 2 at row = 1 and so on\n",
        "\n",
        "Therefore I **subtract 1 from user_id and book_id**, so that they become zero indexed as well and I can referace them by their index "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt-u86EoNXbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X[:, 0] -= 1\n",
        "X[:, 1] -= 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR0f6gHm1NBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify=Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb-BA5RCAO95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2\n",
        "from keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVn_wAjXxFH0",
        "colab_type": "text"
      },
      "source": [
        "![title](https://miro.medium.com/max/1952/1*aP-Mx266ExwoWZPSdHtYpA.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXNYjaYcN7Ph",
        "colab_type": "text"
      },
      "source": [
        "Making the model (based on [Neural Collaborative Filtering](https://arxiv.org/pdf/1708.05031.pdf))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNhIU01h5S0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BookRecommender(Model):\n",
        "    def __init__(self, num_users, num_books, embedding_dim):\n",
        "        super().__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_books = num_books\n",
        "        self.embedding_dim = embedding_dim\n",
        "        \n",
        "        #The paper uses random initialization, but I use he_normal \n",
        "        #because it gives better accuracy for a small change\n",
        "        self.user_embedding = layers.Embedding(num_users, embedding_dim,\n",
        "                                                embeddings_initializer='he_normal',\n",
        "                                                embeddings_regularizer=l2(0.001))\n",
        "        \n",
        "        #Performance of the model can be improved by adding user and book bias terms\n",
        "        #If Yash normally rates the books between 1-3 stars, but he gave some book 5 star, he must really love it!\n",
        "        self.user_bias = layers.Embedding(num_users, 1)\n",
        "        self.book_embedding = layers.Embedding(num_books, embedding_dim, \n",
        "                                               embeddings_initializer='he_normal',\n",
        "                                               embeddings_regularizer=l2(0.001))\n",
        "        \n",
        "        self.book_bias = layers.Embedding(num_books, 1)\n",
        "        classes = ['loved_book', 'liked_book', 'did_not_like']\n",
        "        #Freestyling the number of neurons\n",
        "        self.lin_1 = layers.Dense(2, activation='relu')\n",
        "        self.lin_2 = layers.Dense(4, activation='relu')\n",
        "        self.out_lin = layers.Dense(len(classes), activation='relu')\n",
        "        self.drop_1 = layers.Dropout(0.5)\n",
        "        self.drop_2 = layers.Dropout(0.3)\n",
        "    '''\n",
        "    Instead of passing sparse user vector and a sparse book vector, I pass\n",
        "    the user and book as a pair, so ignore the first layer of the digram\n",
        "    '''\n",
        "    def call(self, ratings, training=False): \n",
        "        user_vector = self.user_embedding(ratings[:, 0])\n",
        "        user_bias = self.user_bias(ratings[:, 0])\n",
        "        book_vector = self.book_embedding(ratings[:, 1])\n",
        "        book_bias = self.book_bias(ratings[:, 1])\n",
        "        #User-book interaction\n",
        "        user_book_dot = layers.Dot(1)([user_vector, book_vector])\n",
        "        x = user_book_dot + user_bias + book_bias\n",
        "        if training:\n",
        "            x = self.lin_2(self.drop_1(self.lin_1(x)))\n",
        "            x = self.drop_2(x)\n",
        "        else: \n",
        "            x = self.lin_2(self.lin_1(x))    \n",
        "        x = self.out_lin(x)\n",
        "        #Softmax to get probabilities\n",
        "        output = layers.Softmax()(x)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXFmiBY9C8Jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "#50 causes overfitting\n",
        "EMBEDDING_DIM = 20\n",
        "model = BookRecommender(TOTAL_USERS, TOTAL_BOOKS, EMBEDDING_DIM)\n",
        "#Adam optimizer used in the paper\n",
        "model.compile(loss=CategoricalCrossentropy(from_logits=True), optimizer=keras.optimizers.Adam(lr=0.001))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdwIwWMI4KUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 100000\n",
        "EPOCHS = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhdwEiFVDZnt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d621d6f-67c9-4878-888d-28b6b6218631"
      },
      "source": [
        "history = model.fit(\n",
        "    x=X_train,\n",
        "    y=Y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(X_test, Y_test)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 2s 37ms/step - loss: 1.0877 - val_loss: 1.0845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrnGi7A8Bl6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "2e04b053-d8a7-44f8-8df0-b054ef4d37cb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"Model loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"train\", \"test\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzyXLRMwCEue",
        "colab_type": "text"
      },
      "source": [
        "Let's save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY786upn1tkW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83c1eec4-0ae0-4da2-e6e2-e94b58c76338"
      },
      "source": [
        "SAVE_PATH = '/content/drive/My Drive/Colab Notebooks/CADABRA/Recommender System/NCF1'\n",
        "model.save(SAVE_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CADABRA/Recommender System/NCF1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty3Hc1QcCrww",
        "colab_type": "text"
      },
      "source": [
        "Function to get predicted ratings for non-rated books for a user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab7f4YS6oPGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predicted_ratings_for(user_id):\n",
        "    books_rated = ratings[ratings.user_id==user_id]\n",
        "    books_not_rated_df = ratings[~ratings.book_id.isin(books_rated.book_id.values)].book_id\n",
        "    books_not_rated = [[x-1] for x in books_not_rated_df.values]\n",
        "    input = np.hstack(([user_id-1])*len(books_not_rated), books_not_rated)\n",
        "    output = model.predict(input)\n",
        "    predicted_ratings = {\n",
        "        'loved_book': output[:, 0], \n",
        "        'liked_book': output[:, 1], \n",
        "        'did_not_like': output[:, 2]\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbEo5sCsp8F8",
        "colab_type": "text"
      },
      "source": [
        "Get top n recommendations for a user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5cPYO9CE5rM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_n_reccomendations_for_user(user_id, n):\n",
        "    predicted_ratings = get_predicted_ratings_for(user_id)\n",
        "    loved_books = predicted_ratings['loved_book']\n",
        "    top_n_books = loved_books.argsort()[-n:][::-1]\n",
        "    book_ids = [x+1 for x in top_n_books]\n",
        "    return book_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8HzjgqoDxYa",
        "colab_type": "text"
      },
      "source": [
        "##**Original Model Implementation**\n",
        "In this section, I will try to implement the model as it is in the paper. Also, I will use Keras Functional API this time to get the flavor of Keras, because last coding the model felt too much like PyTorch "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_jaHF2SHDSl",
        "colab_type": "text"
      },
      "source": [
        "![title](https://miro.medium.com/max/1952/1*aP-Mx266ExwoWZPSdHtYpA.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn1y7OVDBTUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_user = keras.Input(shape=(TOTAL_USERS, ))\n",
        "input_book = keras.Input(shape=(TOTAL_BOOKS, ))\n",
        "\n",
        "user_vector = layers.Embedding(TOTAL_USERS, EMBEDDING_DIM, embeddings_initializer='he_normal', embeddings_regularizer=l2(0.001))(input_user)\n",
        "book_vector = layers.Embedding(TOTAL_BOOKS, EMBEDDING_DIM, embeddings_initializer='he_normal', embeddings_regularizer=l2(0.001))(input_book)\n",
        "\n",
        "x = layers.Concatenate(1)([user_vector, book_vector])\n",
        "x = keras.backend.sum(x, axis=1)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(8, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(3)(x)\n",
        "outputs = layers.Softmax()(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK4YORrYBTWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[input_user, input_book], outputs=outputs, name='book_recommender')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vti6JijLKkE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plotting the model\n",
        "model.compile(loss=CategoricalCrossentropy(from_logits=True), optimizer=keras.optimizers.Adam(lr=0.001))\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnoGmpseMh66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UserBookPairGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, ratings, batch_size=32):\n",
        "        self.batch_size=batch_size\n",
        "        self.user_ids = ratings.user_id.values\n",
        "        self.book_ids = ratings.book_id.values\n",
        "        self.ratings = ratings.rating\n",
        "\n",
        "    def __len__(self):\n",
        "        #Batches per epoch\n",
        "        return len(self.user_ids) // self.batch_size\n",
        "    \n",
        "    #Generates one batch of data\n",
        "    def __getitem__(self, batch_index): \n",
        "        indexes = list(range(batch_index*self.batch_size,(batch_index+1)*self.batch_size))\n",
        "        users_one_hot = np.zeros((self.batch_size, TOTAL_USERS))\n",
        "        #Hacky code\n",
        "        books_one_hot = np.zeros((self.batch_size, TOTAL_BOOKS+1))\n",
        "        #user_id = self.user_id[i] for i in indexes, user_id-1\n",
        "        for e, idx in enumerate(indexes):\n",
        "            user_id, book_id = self.user_ids[idx], self.book_ids[idx]\n",
        "            users_one_hot[e, user_id] = 1\n",
        "            books_one_hot[e, book_id] = 1\n",
        "        one_hot_ratings = self.get_one_hot_ratings(indexes)\n",
        "        return [users_one_hot, books_one_hot], one_hot_ratings\n",
        "    def get_one_hot_ratings(self, indexes):\n",
        "        ratings = self.ratings.iloc[indexes]\n",
        "        a = (ratings == 5).astype(int)\n",
        "        b = (ratings == 4).astype(int)\n",
        "        c = (ratings < 4).astype(int)\n",
        "        return np.stack([a, b, c], axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVr1fkfPzOfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(ratings, stratify=ratings.rating)\n",
        "\n",
        "training_generator = UserBookPairGenerator(train)\n",
        "validation_generator = UserBookPairGenerator(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qSHBtfli5hM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(generator=training_generator, epochs=5, validation_data=validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVW0l24xyl0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"Model loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"train\", \"test\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxLMW6lEylvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SAVE_PATH = '/content/drive/My Drive/Colab Notebooks/CADABRA/NCF2'\n",
        "model.save(SAVE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}